ðŸ“Œ Apache Jira Scraper â€“ Data Pipeline for LLM Training

This project builds a fault-tolerant scraping and data transformation system that collects issue data from Apache Jira, processes it into a clean JSONL format, and prepares it for machine learning or LLM fine-tuning.

âœ… 1. Features & Objectives

âœ” Scrape issues, comments, metadata (status, priority, reporter, assignee, tags etc.)
âœ” Resume scraping automatically using checkpoints (no data loss)
âœ” Handles API failures, retries, timeouts, HTTP 429 & 5xx errors
âœ” Transform raw Jira data into a structured, LLM-ready JSONL corpus
âœ” Adds derived tasks like:
â€ƒâ€ƒâ€¢ Issue classification (Bug/Feature/Docs/Performance)
â€ƒâ€ƒâ€¢ Issue summarization
â€ƒâ€ƒâ€¢ Question-Answer pair generation
âœ” Large datasets are stored in .jsonl instead of .csv to avoid memory issues
âœ” Clean and modular code (scraper.py, transformer.py, utils.py)

âœ… 2. Project Structure

JIRA_SCRAPER/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py          # Scrapes Jira issues, comments, handles pagination & checkpoints
â”‚   â”œâ”€â”€ transformer.py      # Cleans, extracts, summarizes & structures data for LLM
â”‚   â”œâ”€â”€ utils.py            # Retry logic, timeouts, HTTP 429/5xx handling
â”‚   â”œâ”€â”€ export_to_csv.py    # Converts cleaned JSONL â†’ CSV (optional for analysis)
â”‚
â”œâ”€â”€ data/                   # Raw & cleaned data (excluded from Git due to size)
â”‚   â”œâ”€â”€ raw_issues.jsonl
â”‚   â”œâ”€â”€ cleaned_issues.jsonl
â”‚
â”œâ”€â”€ checkpoints/            # Stores last progress & seen issue hashes
â”‚   â”œâ”€â”€ last_checkpoint.json
â”‚   â”œâ”€â”€ seen_hashes.json
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore

âœ… 3. Setup Instructions
âœ… Install & Run Locally
git clone https://github.com/dakshsahu1803/jira-scraper.git
cd jira-scraper

python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

pip install -r requirements.txt

âœ… Run Scraper (Fetch Raw Data)
cd src
python scraper.py
âœ… Run Transformer (Clean Data)
python transformer.py
âœ… (Optional) Export to CSV
python export_to_csv.py

âœ… 4. Architecture & Design
ðŸ”¹ Workflow

Fetch Jira issues using REST API

Save raw data to data/raw_issues.jsonl

Resume scraping using checkpoints & hashes

Transform raw JSON â†’ Clean structured JSONL

Generate summaries, Q/A pairs, issue type classification

Export to CSV if required

ðŸ”¹ Why JSONL?

âœ” Memory-efficient (streamable line-by-line)
âœ” Ideal for LLM training & HuggingFace datasets
âœ” Easier to append and resume work

âœ… 5. Edge Case Handling & Fault Tolerance
Edge Case	Handling Method
HTTP 429 (Too Many Requests)	Automatic wait + retry (exponential backoff)
HTTP 5xx (Server errors)	Retry with delay
Network failure / timeout	try/except + safe retries
Interrupted execution	Resumes via last_checkpoint.json
Duplicate issues	Checked via SHA-256 hash (seen_hashes.json)
Empty or malformed data	Ignored safely â€” no crash
API Rate Limits	Handled using safe_request() in utils.py
âœ… 6. Optimizations

âœ… Batch writes to disk instead of writing each issue
âœ… Checkpoint-based resuming (no duplicates, no restart needed)
âœ… SHA-256 content hashing to skip already processed issues
âœ… Modular, reusable, readable codebase

âœ… 7. Future Improvements

ðŸš€ Use multithreading / asyncio to speed up scraping
ðŸš€ Add Docker support (Dockerfile)
ðŸš€ Add unit tests for scraper and transformer
ðŸš€ Push cleaned dataset to Hugging Face Datasets
ðŸš€ Add command-line arguments for custom projects

âœ… 8. GitHub Guidelines (Important)
data/
checkpoints/
*.jsonl
*.csv
âœ… 10. Authors

Developed by: DAKSH SAHU
Purpose: Assignment â€“ Jira Issue Scraper & Data Preparation for LLMs
Mentors / Reviewers: Naman Bhalla.
